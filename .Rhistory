"core.width = ",
"wavelengths =",
"cmPerPixel")
newFileName <- "/Volumes/data/Lakes380/SurfaceSedimentScans/FullSpectraSurface/createFullSpectra.R"
start <- "#THIS FILE WAS CREATED PROGRAMMATICALLY BY createFullSpectraSurface.R\n\n" %>%
str_c("library(specimR)\n\n") %>%
str_c("library(tidyverse)\n\n") %>%
str_c("library(shiny)")
write(start,
file = newFileName,
append = FALSE)
write(start,
file = newFileName,
append = FALSE)
allRuns <- list.files(startDir)
allRuns
for(r in allRuns){
tr <- list.files(file.path(startDir,r,"products"),full.names = TRUE)
if(any(grepl(tr,pattern = "roi"))){
reproc <- readLines(file.path(startDir,r,"products","reprocess.R"))
ii <- which(grepl(reproc,pattern = "indices ="))
reproc[ii] <- newIndices
#output dir.
odi <- which(grepl(reproc,pattern = 'output.dir'))
odl <- reproc[odi]
odlNew <- str_replace(odl,outDirSearch,outDirBase)
newDir <- str_split(odlNew," = ")[[1]][2] %>% str_remove("',") %>% str_remove("'")
reproc[odi] <- odlNew
dir.create(dirname(newDir))
dir.create(newDir)
for(tri in torem){
wtri <- which(grepl(pattern = tri,reproc))
reproc <- reproc[-wtri]
}
#add new line
lastComma <- max(str_locate_all(reproc[length(reproc)],pattern = ",")[[1]])
substr(reproc[length(reproc)],lastComma,lastComma) <- ")"
write(reproc,
file = newFileName,
append = TRUE)
write("\n\n",
file = newFileName,
append = TRUE)
}
}
source("~/Downloads/createFullSpectraSurface.R")
R.version
sessionInfo()
library(tidyverse)
ff <- list.files("~/Download/drive-download-20210721T160335Z-001/",recursive = TRUE)
ff
ff <- list.files("~/Download/drive-download-20210721T160335Z-001/",recursive = TRUE,pattern = "depthTable.csv")
ff
path <- ff[22]
dat <- readr::read_csv(path)
ff <- list.files("~/Download/drive-download-20210721T160335Z-001/",
recursive = TRUE,
full.names = TRUE,
pattern = "depthTable.csv")
path <- ff[22]
dat <- readr::read_csv(path)
dat
dat <- readr::read_csv(path) %>%
dplyr::select(-pixel)
dat
dat <- readr::read_csv(path) %>%
dplyr::select(-pixel) %>%
tidyr::pivot_wider(names_from = position, values_from = cm)
dat
path
ff <- list.files("~/Download/DUNCA1 R Script HS Data/",
recursive = TRUE,
full.names = TRUE,
pattern = "depthTable.csv")
ff
path <- ff[5]
dat <- readr::read_csv(path) %>%
dplyr::select(-pixel) %>%
tidyr::pivot_wider(names_from = position, values_from = cm)
dat
#parse path to get core name
str_extract(path,"^/(?:\\.|[^/\\])*/")
#parse path to get core name
str_extract(path,"[^/(?:\\.|[^/\\])*/]")
#parse path to get core name
str_extract(path,"[^/(?:\\.|[^/\\])*/]")
#parse path to get core name
str_extract(path,"[^/(?:.|[^/])*/]")
path
#parse path to get core name
str_extract(path,"[^//(?:.|[^/])*//]")
#parse path to get core name
str_extract(path,"[^//*//]")
#parse path to get core name
str_extract(path,"[^//?*//]")
#parse path to get core name
str_extract(path,"[^//*?//]")
#parse path to get core name
str_extract(path,"[^////]")
#parse path to get core name
str_extract(path,"[^//]")
#parse path to get core name
str_extract(path,"[//]")
#parse path to get core name
str_extract(path,"[/*/]")
#parse path to get core name
str_extract(path,"^/")
#parse path to get core name
str_extract(path,"*^/")
#parse path to get core name
str_extract(path,"[*^/]")
#parse path to get core name
str_extract(path,"[^/*]")
#parse path to get core name
str_extract(path,"^[^\/]*\/[^\/]*")
#parse path to get core name
str_extract(path,"[^[^\/]*\/[^\/]*]")
#parse path to get core name
str_extract(path,"[^[^/]*\/[^/]*]")
#parse path to get core name
str_extract(path,"[^[^/]*/[^/]*]")
#parse path to get core name
str_extract(path,"[^[^/]*[^/]*]")
#parse path to get core name
str_extract(path,"^[^/]*[^/]*")
#parse path to get core name
str_extract(path,"^[^/]*[^/]*")
#parse path to get core name
str_extract(path,"[A-Z][A-Z}*")
#parse path to get core name
str_extract(path,"[A-Z][A-Z]*")
path
#parse path to get core name
str_extract(path,"^.*\/(.*)\/.*\/$")
#parse path to get core name
str_extract(path,"^.*\\/(.*)\\/.*\\/$")
#parse path to get core name
str_extract(path,"^.*/(.*)/.*/$")
#parse path to get core name
str_extract(path,"^.*/(.*)/.*/")
#parse path to get core name
str_extract(path,"^.*/(.*)/.*/$")
#parse path to get core name
str_extract(path,".*/(.*)/.*/$")
#parse path to get core name
str_extract(path,"*/(.*)/.*/$")
#parse path to get core name
str_extract(path,".*/.*/.*/$")
#parse path to get core name
str_extract(path,".*/.*/.*/")
#parse path to get core name
str_extract(path,"$.*/.*/.*/")
#parse path to get core name
str_extract(path,"^.+/\K[^/]+(?=/[^/]+/)")
#parse path to get core name
str_extract(path,"^.+/[^/]+(?=/[^/]+/)")
path <- "/Users/nicholas/Download/DUNCA1 R Script HS Data//DUNCA1_LC4U_1A/products/"
path
#parse path to get core name
str_extract(path,"^.+/[^/]+(?=/[^/]+/)")
path <- "/Users/nicholas/Download/DUNCA1 R Script HS Data/"
#parse path to get core name
str_extract(path,"^.+/[^/]+(?=/[^/]+/)")
#parse path to get core name
str_extract(path,"^.+/[^/]+(?=/[^/]+/)") %>%
dirname()
#parse path to get core name
str_extract(path,"^.+/[^/]+(?=/[^/]+/)") %>%
basename()
path <- ff[5]
path %>%
basename()
path %>%
dirname()
path %>%
dirname() %>%
dirname()
path %>%
dirname() %>%
dirname() %>%
basename()
dat <- readr::read_csv(path) %>%
dplyr::select(-pixel) %>%
tidyr::pivot_wider(names_from = position, values_from = cm)
#parse path to get core name
dat$corename <- path %>%
dirname() %>%
dirname() %>%
basename()
dat <- dplyr::select(corename,everything())
pullDepthData <- function(path){
dat <- readr::read_csv(path) %>%
dplyr::select(-pixel) %>%
tidyr::pivot_wider(names_from = position, values_from = cm)
#parse path to get core name
dat$corename <- path %>%
dirname() %>%
dirname() %>%
basename()
dat <- dplyr::select(corename,everything())
}
dat
dat <- dplyr::select(corename,everything())
#parse path to get core name
dat$corename <- path %>%
dirname() %>%
dirname() %>%
basename()
dat
dat <- dplyr::select(corename,everything())
dat <- dplyr::select(dat,corename,everything())
dat
source("~/.active-rstudio-document", echo=TRUE)
test
ff
ff <- str_detect(ff,"photos")
ff <- list.files("~/Download/DUNCA1 R Script HS Data/",
recursive = TRUE,
full.names = TRUE,
pattern = "depthTable.csv")
hp <- str_detect(ff,"photos")
hp
source("~/.active-rstudio-document", echo=TRUE)
test
#Analysis of temp data for NE N America during Early Holocene
library(lipdR) #to read and interact with LiPD data
library(geoChronR) #for plotting mostly
library(magrittr) #we'll be using the magrittr pipe ( %>% ) for simplicity
library(dplyr) #and dplyr for data.frame manipulation
library(ggplot2) #for plotting
library(compositeR) #remotes::install_github("nickmckay/compositeR")
library(foreach) #for parallel processing
library(doParallel)#for parallel processing
#First make a stack plot
D <- readLipd("https://lipdverse.org/Temp12k/1_0_2/Temp12k1_0_2.zip")
TS <- extractTs(D)
TS <- extractTs(D) %>% #extract to lipd-ts
as.lipdTsTibble()
View(TS)
TS <- extractTs(D) %>% #extract to lipd-ts
as.lipdTsTibble() %>% # and the then to lipd-ts-tibble for filtering
filter(between(geo_longitude,-90,-50)) %>%  #only NE NA longitudes
filter(between(geo_latitude,35,55)) %>%  #between 35 and 55 N
filter(interpretation1_variable == "T") %>% #only variables sensitive temperature
filter(paleoData_medianRes12k < 200) %>% #only time series at highres
filter(interpretation1_seasonalityGeneral == "summer+") %>% #only summer proxies
as.lipdTs() #back to TS for compositeR
L <- D$`117_723A.Godad.2011`
L$paleoData[[1]]$measurementTable[[1]]$age$values
ts <- extractTs(L) %>% ts2tibble()
View(ts)
library(magrittr)
library(ggplot2)
library(actR)
library(neotoma2)
library(tidyverse)
library(lipdR)
library(geoChronR)
remotes::install_github("neotomaDB/neotoma2")
library(magrittr)
library(ggplot2)
library(actR)
library(neotoma2)
library(tidyverse)
library(lipdR)
library(geoChronR)
L <- neotoma2::get_datasets(53327) %>% #Find the site of interest
neotoma2::get_downloads()  #download the data for this site
L_lip=lipdR::neotoma2lipd(L) #convert the site object into a LiPD object
mapLipd(L_lip,map.type = "stamen",extend.range = 5)#visualize the location
mapLipd(L_lip,map.type = "stamen",extend.range = 5)#visualize the location
my_counts<- neotoma2::samples(L)
counts=pivot_wider(my_counts, names_from = variablename, values_from = value, values_fill = NA, id_cols=age)
lat=L_lip[["geo"]][["latitude"]]
L_lip$chronData[[1]]$measurementTable[[1]]$age14C
L_lip$chronData[[1]]$measurementTable[[1]]$age
L_lip <- geoChronR::runBacon(L_lip,
lab.id.var = 'neotomaChronConrolId',
age.14c.var = 'age14C',#for rest: 'age14C'
age.14c.uncertainty.var = 'age14CUnc',#for rest: 'age14CUnc'
age.var = 'age', #for bambili: 'age'
age.uncertainty.var = 'ageUnc',#for bambili 'ageUnc'
depth.var = 'depth',
cc=3,
reservoir.age.14c.var = NULL,
reservoir.age.14c.uncertainty.var = NULL,
rejected.ages.var = NULL,
plot.pdf = FALSE,
accept.suggestions = TRUE)
L_lip <- geoChronR::runBacon(L_lip,
lab.id.var = 'neotomaChronConrolId',
age.14c.var = 'age14C',#for rest: 'age14C'
age.14c.uncertainty.var = 'age14CUnc',#for rest: 'age14CUnc'
age.var = NULL, #for bambili: 'age'
age.uncertainty.var = NULL,#for bambili 'ageUnc'
depth.var = 'depth',
cc=3,
reservoir.age.14c.var = NULL,
reservoir.age.14c.uncertainty.var = NULL,
rejected.ages.var = NULL,
plot.pdf = FALSE,
accept.suggestions = TRUE)
styler:::style_selection()
styler:::style_selection()
# Function to create master depth table
create_core_depth_table <- function(directory = NA_character_) {
# List depth table files in the root drive directory
depth_data <- fs::dir_ls(paths, regexp = "depthTable", recurse = TRUE) |>
# Filter so paths to photos are not recorded
fs::path_filter(regexp = "photos", invert = TRUE) |>
# Read files
vroom::vroom(id = "path", .name_repair = "universal")
# List files with measurements in the root drive directory
spectral_data <- fs::dir_ls(path, regexp = "spectralIndices", recurse = TRUE) |>
# Read files
vroom::vroom(id = "path", .name_repair = "universal")
# Translate depths
roi_top <- depth_data |>
# Get only top of the ROI
dplyr::filter(position == "roiTop") |>
# Get ROI number
dplyr::mutate(roi = stringr::str_extract(path, pattern = "roi-[:digit:]+"))
# Join with the spectral indices
translated_data <- spectral_data |>
# Get ROI number
dplyr::mutate(roi = stringr::str_extract(path, pattern = "roi-[:digit:]+")) |>
# Full join
dplyr::left_join(roi_top, by = "roi") |>
# Composite depth
dplyr::mutate(composite = depth + cm, .after = depth)
# Return data
return(translated_data)
}
# Function to create master depth table
create_composite_drive <- function(directory = NA_character_) {
# List depth table files in the root drive directory
depth_data <- fs::dir_ls(paths, regexp = "depthTable", recurse = TRUE) |>
# Filter so paths to photos are not recorded
fs::path_filter(regexp = "photos", invert = TRUE) |>
# Read files
vroom::vroom(id = "path", .name_repair = "universal")
# List files with measurements in the root drive directory
spectral_data <- fs::dir_ls(path, regexp = "spectralIndices", recurse = TRUE) |>
# Read files
vroom::vroom(id = "path", .name_repair = "universal")
# Translate depths
roi_top <- depth_data |>
# Get only top of the ROI
dplyr::filter(position == "roiTop") |>
# Get ROI number
dplyr::mutate(roi = stringr::str_extract(path, pattern = "roi-[:digit:]+"))
# Join with the spectral indices
translated_data <- spectral_data |>
# Get ROI number
dplyr::mutate(roi = stringr::str_extract(path, pattern = "roi-[:digit:]+")) |>
# Full join
dplyr::left_join(roi_top, by = "roi") |>
# Composite depth
dplyr::mutate(composite = depth + cm, .after = depth)
# Return data
return(translated_data)
}
create_composite_drive("C:\Users\maury\OneDrive\Praca\Data\proxy_datasets\04_hyperspectral\Stoneman-STL_us\normalization\data\1A\STL14_1A_3C_top_2022-11-03_17-39-55")
create_composite_drive("C:/Users/maury/OneDrive/Praca/Data/proxy_datasets/04_hyperspectral/Stoneman-STL_us/normalization/data/1A/STL14_1A_3C_top_2022-11-03_17-39-55")
# Function to create master depth table
create_composite_drive <- function(directory = NA_character_) {
# List depth table files in the root drive directory
depth_data <- fs::dir_ls(directory, regexp = "depthTable", recurse = TRUE) |>
# Filter so paths to photos are not recorded
fs::path_filter(regexp = "photos", invert = TRUE) |>
# Read files
vroom::vroom(id = "path", .name_repair = "universal")
# List files with measurements in the root drive directory
spectral_data <- fs::dir_ls(directory, regexp = "spectralIndices", recurse = TRUE) |>
# Read files
vroom::vroom(id = "path", .name_repair = "universal")
# Translate depths
roi_top <- depth_data |>
# Get only top of the ROI
dplyr::filter(position == "roiTop") |>
# Get ROI number
dplyr::mutate(roi = stringr::str_extract(path, pattern = "roi-[:digit:]+"))
# Join with the spectral indices
translated_data <- spectral_data |>
# Get ROI number
dplyr::mutate(roi = stringr::str_extract(path, pattern = "roi-[:digit:]+")) |>
# Full join
dplyr::left_join(roi_top, by = "roi") |>
# Composite depth
dplyr::mutate(composite = depth + cm, .after = depth)
# Return data
return(translated_data)
}
create_composite_drive("C:/Users/maury/OneDrive/Praca/Data/proxy_datasets/04_hyperspectral/Stoneman-STL_us/normalization/data/1A/STL14_1A_3C_top_2022-11-03_17-39-55")
test <- create_composite_drive("C:/Users/maury/OneDrive/Praca/Data/proxy_datasets/04_hyperspectral/Stoneman-STL_us/normalization/data/1A/STL14_1A_3C_top_2022-11-03_17-39-55")
View(test)
fs::path_sanitize("C:\Users\maury\OneDrive\Praca\Data\proxy_datasets\04_hyperspectral\Stoneman-STL_us\normalization\data\1A\STL14_1A_3C_top_2022-11-03_17-39-55")
fs::path_tidy("C:\Users\maury\OneDrive\Praca\Data\proxy_datasets\04_hyperspectral\Stoneman-STL_us\normalization\data\1A\STL14_1A_3C_top_2022-11-03_17-39-55")
directories <- fs::dir_ls("C:/Users/maury/OneDrive/Praca/Data/proxy_datasets/04_hyperspectral/Stoneman-STL_us/normalization/data\1A")
directories <- fs::dir_ls("C:/Users/maury/OneDrive/Praca/Data/proxy_datasets/04_hyperspectral/Stoneman-STL_us/normalization/data/1A")
directories
test <- purrr::map(directories, \(x) create_composite_drive(x))
directories <- fs::dir_ls("C:/Users/maury/OneDrive/Praca/Data/proxy_datasets/04_hyperspectral/Stoneman-STL_us/normalization/data/1A") |>
fs::path_filter(regexp = "bot")
test <- purrr::map(directories, \(x) create_composite_drive(x))
directories
directories <- fs::dir_ls("C:/Users/maury/OneDrive/Praca/Data/proxy_datasets/04_hyperspectral/Stoneman-STL_us/normalization/data/1A") |>
fs::path_filter(glob = "bot")
directories <- fs::dir_ls("C:/Users/maury/OneDrive/Praca/Data/proxy_datasets/04_hyperspectral/Stoneman-STL_us/normalization/data/1A") |>
fs::path_filter(regexp = "bot", invert = TRUE)
test <- purrr::map(directories, \(x) create_composite_drive(x))
test$`C:/Users/maury/OneDrive/Praca/Data/proxy_datasets/04_hyperspectral/Stoneman-STL_us/normalization/data/1A/STL14_1A_10C_top_2022-11-05_17-12-16`
View(test)
View(test[["C:/Users/maury/OneDrive/Praca/Data/proxy_datasets/04_hyperspectral/Stoneman-STL_us/normalization/data/1A/STL14_1A_10C_top_2022-11-05_17-12-16"]])
styler:::style_active_file()
#' @param directory character path to selected drive
#' @param .tofile if TRUE write output to file
#'
#' @return a tibble with composite record for selected drive
#' @export
#'
#' @description If there are multiple ROIs within single drive, merge them into composite
#' Works with purrr::map for multiple drives if directory is a vector of paths
#'
#' @examples
create_composite_drive <- function(directory = NA_character_, .tofile = TRUE) {
# List depth table files in the root drive directory
depth_data <- fs::dir_ls(directory, regexp = "depthTable", recurse = TRUE) |>
# Filter so paths to photos are not recorded
fs::path_filter(regexp = "photos", invert = TRUE) |>
# Read files
vroom::vroom(id = "path", .name_repair = "universal")
# List files with measurements in the root drive directory
spectral_data <- fs::dir_ls(directory, regexp = "spectralIndices", recurse = TRUE) |>
# Read files
vroom::vroom(id = "path", .name_repair = "universal")
# Translate depths
roi_top <- depth_data |>
# Get only top of the ROI
dplyr::filter(position == "roiTop") |>
# Get ROI number
dplyr::mutate(roi = stringr::str_extract(path, pattern = "roi-[:digit:]+"))
# Join with the spectral indices
translated_data <- spectral_data |>
# Get ROI number
dplyr::mutate(roi = stringr::str_extract(path, pattern = "roi-[:digit:]+")) |>
# Full join
dplyr::left_join(roi_top, by = "roi") |>
# Composite depth
dplyr::mutate(composite = depth + cm, .after = depth)
# Should tibble be written to file
if (.tofile == TRUE) {
readr::write_csv(x = translated_data, file = paste0(directory, "composite.csv"))
} else {
# Return data
return(translated_data)
}
}
directories <- fs::dir_ls("C:/Users/maury/OneDrive/Praca/Data/proxy_datasets/04_hyperspectral/Stoneman-STL_us/normalization/data/1A") |>
fs::path_filter(regexp = "bot", invert = TRUE)
test <- purrr::map(directories, \(x) create_composite_drive(x))
#' @param directory character path to selected drive
#' @param .tofile if TRUE write output to file
#'
#' @return a tibble with composite record for selected drive
#' @export
#'
#' @description If there are multiple ROIs within single drive, merge them into composite
#' Works with purrr::map for multiple drives if directory is a vector of paths
#'
#' @examples
create_composite_drive <- function(directory = NA_character_, .tofile = TRUE) {
# List depth table files in the root drive directory
depth_data <- fs::dir_ls(directory, regexp = "depthTable", recurse = TRUE) |>
# Filter so paths to photos are not recorded
fs::path_filter(regexp = "photos", invert = TRUE) |>
# Read files
vroom::vroom(id = "path", .name_repair = "universal")
# List files with measurements in the root drive directory
spectral_data <- fs::dir_ls(directory, regexp = "spectralIndices", recurse = TRUE) |>
# Read files
vroom::vroom(id = "path", .name_repair = "universal")
# Translate depths
roi_top <- depth_data |>
# Get only top of the ROI
dplyr::filter(position == "roiTop") |>
# Get ROI number
dplyr::mutate(roi = stringr::str_extract(path, pattern = "roi-[:digit:]+"))
# Join with the spectral indices
translated_data <- spectral_data |>
# Get ROI number
dplyr::mutate(roi = stringr::str_extract(path, pattern = "roi-[:digit:]+")) |>
# Full join
dplyr::left_join(roi_top, by = "roi") |>
# Composite depth
dplyr::mutate(composite = depth + cm, .after = depth)
# Should tibble be written to file
if (.tofile == TRUE) {
readr::write_csv(x = translated_data, file = paste0(directory, "/composite.csv"))
} else {
# Return data
return(translated_data)
}
}
test <- purrr::map(directories, \(x) create_composite_drive(x))
directories <- fs::dir_ls("C:/Users/maury/OneDrive/Praca/Data/proxy_datasets/04_hyperspectral/Stoneman-STL_us/normalization/data/1B") |>
fs::path_filter(regexp = "bot", invert = TRUE)
test <- purrr::map(directories, \(x) create_composite_drive(x))
test <- purrr::map(directories, \(x) create_composite_drive(x))
directories <- fs::dir_ls("C:/Users/maury/OneDrive/Praca/Data/proxy_datasets/04_hyperspectral/Stoneman-STL_us/normalization/data/1B") |>
fs::path_filter(regexp = "bot", invert = TRUE)
test <- purrr::map(directories, \(x) create_composite_drive(x))
